# Personalized Voice Prompts for Training

1. revert that last commit
2. open parenthesis
3. wrap the function in a try catch block
4. semicolon
5. backslash
6. dot
7. underscore
8. equals
9. close brace
10. git status
11. open brace
12. open /src/main.py
13. run grep search for normalize audio
14. git push origin main
15. switch to the v2 architecture
16. ; 
17. change the variable to snake case
18. / 
19. close parenthesis
20. Okay, start and do not stop until all acceptance criteria is met.
21. Does all that research help in any way in determining how we should proceed in terms of our fine tuning?
22. What? Just the case can change WER from 1 to 0? That does not make any sense.
23. Add a guidance note about not stopping until the entire verification criteria is met. Can you do all of the verification by yourself?
24. Content from @nvim/init.lua:
25. At least put it as documentation in top of the doc string in init.lua
27. And then why did you stop?
28. Look @plan.md @docs/experiment_plan.md @docs/moonshine.md exp_2_3_v2_bridge_focus/experiment.log. Do you think this is going to work in terms of training?
29. Go search for the docs for moonshine including any research docs. Download it, read it and then create the docs, put direct links to it in the doc
30. Is the new plan better? plan.md
31. Isn't your experiment plan based on the wrong model?
32. In the diff view how do I stage, unstage?
33. You completely got rid of the previous guidance section.
34. Put a docstring at the top of the file on all major key maps.
35. No, you should make all your decisions by yourself. Again confirm to me that you will not stop for anything
36. First update the plan. And make sure you confirm to me that you will not stop until the whole plan is done
37. Are the JSON files generated by it needed to be persisted in Git?
39. Now tell me again when you will ask me a question?
40. Why doesn't it appear when I do ? in neotree?
41. But we specifically want to do it on V2
42. You just said to me that all models are v2 First tell me what is correct.
43. Are any of your changes documented?
44. is the training still really improving?
45. Is there some way to verify that those last fifty are easier?
46. WHY WHY do you keep making changes
47. give me your plan first
48. That is when the plan stops. Asked when will you stop once you start?
49. Why is the moonshine document so bare now? u removed all details.
50. let's actually reread the blog post. Tell me if there's something obviously incorrect?
51. Leave it. Does it end abruptly?
52. Look @docs/training_report.md @docs/training.md @docs/known_issues.md . Why are we not getting any gains in training?
53. Read again the guidance criteria and tell me what you will do and when you will stop.
54. I fixed somethings but not others so re-review. Convert the Next diagram to be for app router. Why is Hono a server, it does not come with a server built in?
55. I don't want any tests for logging. Are these tests actual functional tests?
56. Now updatge @AGENTS.md instructions on how to use the just file. And specific instructions to only use the just file for running and polling experiments.
57. No I only want shortcut window or panel for fugitive. Alternatively, put shortcuts in the top of init.lua as docstrings or something
58. I asked a question, do not do anything until you have clarified how you're going to do stuff.
59. Is any thing even running?
60. fix the typose, do nothing else
61. Put this in the known issues document.
62. when I go into visual mode to delete somethiong, it is also copied to clipboard preventing me from copying something else to thjat location. what is the ciorrect way to fix this
63. do you have access to our transcripts. For example in ~/.gemini. Can you search in detail and create the raw data to use for starting recording process
64. Now will you again be lazy on my query? Create technical minded data relevant for the recording session by detailed going through transcripts
65. why did you pick batch 260?
66. Now look at the logs that we have right now of ongoing training. What can you conclude from reading those logs?
67. Is that intentional to have the last fifty be easier?
68. Look @docs/training_report.md. Why do you think no progress was made in the training?
69. After training is complete, how would inference look like? Is there a way of optimizing inference? Does that involve changing the data into a different format?
70. REview @_posts/2026-02-15-an-introduction-to-react-next-from-a-backend-engineer.md its a first draft. What are your initial thoughts
71. Can you add a training implications section In the moonshine doc? and in detail add everything that you just said to me.
72. why do I not see a diff view using fugitive. That's the main thing I want, a good diff view
73. Considering how much WER was improving towards the end, should we use more batches?
74. I don't know what you are doing. The file being opened is the before change verfsion
75. No edits at all. Only discussions. Is @docs/experiment_plan.md Account for all that you mentioned.
76. create docs/personalized_training.md. put everything you have learnt until now in there. Then add a full plan including all tooling etc needed to do the custom training
77. move @docs/personalized_training.md to docs/personalized/training.md. Create another doc in there called toolong.md. In the doc write what tooling to build using python for creating the training dataset
78. Content from @.gitignore:
79. Tell me again what the plan guidance was?
80. You're just going around in circles. = E447: Can't find file "vim/keymap/set" in path Press ENTER or type command to continue
81. That is not what I want. don't want to be notified. You are supposed to keep running it and keep checking and if something does not work, change it and redo an experiment. Stop saying other stuff and tell me do you understand?
82. gf doesn't do anythign, do I have to be in some mode?
83. but now the file is open as 2 splits
84. How would we interact with the model using voice on a Mac? I'm talking more about UX. Can we just run a CLI and it can be used for us to interact with it?
85. how do I copy the filename from neotree?
86. So my description of Next is incorrect? The server does not in fact send HTML + Javascript
87. What does stopping only after everything is done mean?
88. you will run out of tokens if you read that file full
89. is there another theme or anything really that has this in built as a plugin?
90. @nvim/init.lua why is vim fugitive not doing anything. It says - E492: Not an editor command: Gstatus
91. Would it help if you write the moonshine docs? Even though it does not do Lora?
92. is mermaid the best way to illustrate this. Think harder but don't change anything. Tell me what other ways we could do this
93. surely jekyll or minimal mistakes has a plugin for this
94. Why do you keep doing something that requires me to approve - `Allow execution of: 'cat, heredoc (<<), redirection (>), uv'?`. You already have a wide approval list, why do you need to do this very specific kind of approval?
95. Can you first update logging to make sure that it shows when it's showing domain one and held out one?
96. Add your suggestions to the experiment plan document as a new experiment line.
97. read @plan.md Can this plan be done with the just file?
98. Content from @docs/experiment_plan.md:
99. put a to do docstring at the top of the build domain manifest script about this issue. put in known issues document. Don't put a single or two liner, be a little more detailed.
100. review @refactor.md and the codebase. Will it fix the current issues?
101. Why do you keep doing this? Why do you not do the timeout polls?
102. DIAGNOSIS. ONLY ASKED FOR DIAGNOSIS
103. Can we do that as a separate package with a separate dependency group? How would you do that in the current project?
104. neovim, how do I copy the filename from neotree?
105. Read docs/experiment_plan.md and Current state of training. Run logs are available in outputs folder. Can you diagnose why no improvements are happening?
106. Nope don't want this - setup_logging(output_dir="outputs") . The application code should not change
107. Redo both experiment plan and plan.md. Make sure you attend only the correct places for experiment plan. Make sure you specify why you are making this plan.
108. Again, why - `Allow execution of: 'uv, redirection (>), redirection (>)'? `
109. Include in @docs/training.md reporint template to specify time taken by training
110. Is @plan.md a better plan now?
111. what is FCP?
112. write a voice.md. Write your full plan in there.
113. use gh cli if you have to. Find the model.
114. Content from @plan.md:
115. Review @docs/training.md Is this type of trainingfeasible to do on a Mac M3.
116. how would you configure logging_utils to say in additino log to some log file in outputs? Should have a timestamp in name, should start with what command was used to start the application?
117. poll yourself. Just don't run commands that keep asking for approval.
118. You did not keep your shell open. Why are you doing this? Why can't you keep it open?
119. WHY are you so lazy. I could find relevant files here - ~/.gemini/tmp/. DO NOT do anythong. Tell me why you are so lkazy
120. And will you stop at any point? And when will you stop?
121. Content from @tuning_plan.md:
122. do not use streaming model. Change everything else.
123. Look @plan.md @docs/moonshine.md. We seem to have been training the wrong model. Based on whatever you have learned, is the plan correct? Also look @docs/experiment_plan.md
124. Can you use the just command for polling?
125. Rewrite plan.md with your plan. Make sure it has verification and acceptance criteria. Make sure acceptance critera has training report. What would be the hypothesis?
126. Wait, did you make changes to code? REvert them. I asked you to debug, not to change code.
127. Fix the linting errors.
128. Look @docs/training.md and @docs/experiment_plan.md What do you think is the target we want to achieve?
129. Why do you have to use environment variables everywhere? like in model_utils. Why are you not explicitly using arguments? Remove environment variables where arguments should be used.
130. Yes, and do not stop.
131. What is the build manifest for?
132. what is this going around in circles
133. IS the revised @plan.md better?
134. Read the document again @docs/experiment_plan.md It debunked your theory.
135. where are you seeing these numbers 11.69%, 11.87%?
136. @docs/experiment_plan.md not plan.md
137. Make the docs string in that file have all the things that you just said.
138. Read exp_2_3_v2_bridge_focus/experiment.log. Don't just tail it. What does the current state of the experiment tell you?
139. I will remove it since it brings nothing to the table. Now explain the significance of RSC in the diagram. Why is it important that we point out RSC?
140. Look at all the recent log files. Do any of the experiment variations yield any benefits?
141. does the current blog setup allow introducing a light/dark theme toggle?
142. Write a detailed docs/inference.md With your findings and properly structured.
143. I have removed your changes. What do you think I meant when I said add a new section for your suggested experiment plan. How do you think it makes any sense without having justification for doing a specific line of experiments?
144. Read @plan.md @docs/experiment_plan.md Do you understand the plan? Once you start, when will you stop? Will you stop to ask questions? You stop in between phases? What will you do in your execution?
145. No, do not add a fix. but create a specific document for this to note down issues like this.
146. Write a verification criteria and stopping criteria into the plan. Can all of that be done with the existing state of the package?
147. Why do you have to do things where I have to approve. You have a wide approval already - Allow execution of: 'mkdir, uv, redirection (>), redirection (>)'?
148. did not ask you to make changes. Asked you to diagnose. I have reverted all your changes
149. Does @plan.md account for these?
150. You can use timeout polls.
151. gf in vsplit - E447: Can't find file "vim/keymap/set" in path Press ENTER or type command to continue
152. in nvim, how can I refresh an open file for eg a log file?
153. You're not doing a very good job. WER evaluation keeps happening at various intervals. You only looked at the last interval. You did not do a very good job researching the logs.
154. why do you insist on not using uv
155. What do you think next steps are?
156. No files matching the criteria were found or all were skipped.
157. Read @docs/training_report.md And review the code base. Why are we not getting any improvements?
158. Stop reading continuously. Just poll at some second intervals.
159. Did you stop monitoring? You're supposed to do this end to end.
160. That is not what I meant, and you are completely going in the wrong direction. The current objective is to prove that fine tuning works at all. What I told you is the eventual objective.
161. Can you create a just file? Can you add tasks the just file for running long running experiments. One task should be for running the experiment, another task for pulling the logs of that experiment.
162. .temp ToDo*
163. review again
164. run_20260219_140512.log - Why do the number of samples stay the same? I thought the domain manifest now has more samples.
165. Now based on everything in the plan Once you start working, then will you stop?
166. It seems to be plateauing. Does the lower learn rate not mean that it's actually struggling to learn?
167. Read @tuning_plan.md, what would you change?
168. IF a process is working in the background but it does logging, can we see the logs somehow outside of the process?
169. Look at all of our keymaps. For yazi, can we instead use leader - yz. And if not, why not?
170. STOP telling me things, and do it. You task is clear, your goal is clear, why DO YOU KEEP stopping
171. Only update the docs and the plan.
172. Look @plan.md @docs/training_report.md @docs/training.md @docs/known_issues.md . Why are we not getting any gains in training?
173. look at the other posts in the folder. Then come back to this post and review again, and give me all your thoughts
174. Content from @docs/training_report.md:
175. And so the assumption is that after the final loss we will get better WER?
176. write your review to review.md
177. Training should have been V2 from the start. What should we change about the documentation, etcetera?
178. Are there any tests you could have added?
179. @docs/experiment_plan.md we ran all these hypothesis. No improvements are happening. Diagnose, no changes
180. Update the experiment plan. Put everything including justification in there. Then create a new plan in plan.md. Make sure your hypothesis is placed properly in there. Make sure all criteria as in the existing plan.md is there.
181. Content from @docs/known_issues.md:
182. Did you just stop? What did we agree on?
183. don't do head for that file, its massive
184. Content from @_posts/2026-02-15-an-introduction-to-react-next-from-a-backend-engineer.md:
185. Make sure arguments are logged.
186. continue. you are trying to read a too big file. Make sure you use head, tail etc To not read too big of a file.
187. Let's stay on DORA. Do you have some understanding of why it's not improving?
188. I don't think the job is running. Make sure the job is running and then keep pulling. You should never stop Until you have proven that plan.md works
189. can I also get shortcuts view to see what I can do inside the diff view from fugitive?
190. Look @plan.md @docs/experiment_plan.md @docs/moonshine.md exp_2_4_v2_true_bridge/experiment.log. Will this achieve what we want to achieve?
191. can you stick to using uv
192. Why do you think loss is improving but WER is not?
193. actually forget that. your diagrams are excellent
194. Look @docs/experiment_plan.md Why are we still unable to improve any benchmarks?
195. Is there some way to figure out what then is the loss improvement actually affecting?
196. That moonshine paper seems very old. Are you sure it's the v2 paper. Did you actually read it?
197. Read @docs/known_issues.md Is that consistent with what you are planning?
198. What is the correct way to remove sys.path and PYTHONPATH issues in the current repo. Do not actually make any changes first investigate, Do any research if necessary and come back and report.
199. Content from @docs/training.md:
200. No, you will not stop if you are stuck. You will use best practices to unstuck yourself.
201. I don't see most of what you just shared with me in the document that you created.
202. Content from @docs/moonshine.md:
203. If we continue down this training route, how big of a model can we train?
204. System: Please continue.
205. Didn't we agree to use just commands?
206. I didn't see you download any paper. Show me actual citation data from inside the paper to verify that you actually read the paper.
207. Merge all make files into the just file.
208. You have the capability to read PDFs, download it, read it, do not give me abstract data.
209. Content from @docs/personalized_training.md:
210. Look @outputs/run_20260219_12842.log. Based on how the training is progressing, Do you learn anything from just the logs?
211. Based on everything you understand, can you update the experiment plan and the execution plan? And do nothing else.
212. Polling should be via a timeout
213. You're not polling. What is it that I am failing to tell you?
214. Based on your moonshine document, are we even training the correct model?
215. in a diff view in git fugitive how do I go to that file at that position
216. Now think hard. Why would adding LoRa help in increasing performance instead of increasing the size of the model? Surely the researchers would have done full optimization?
217. Content from @refactor.md:
218. No, I even want the UX code itself to be a separate package. Tell me what that separate package will look like?
219. What if I'm already inside the CLI? 
